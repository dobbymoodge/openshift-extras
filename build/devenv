#!/usr/bin/env ruby

$: << File.expand_path(File.dirname(__FILE__))
require 'origin_constants'
#unless ENV['SKIP_SETUP']
#  require 'lib/openshift/setup_helper'
#  SetupHelper::ensure_build_requirements
#end
require File.join('lib', '..', '..', '..', "#{DEV_TOOLS_REPO}", 'build', 'lib', 'openshift')
require File.join('lib', '..', '..', '..', "#{DEV_TOOLS_REPO}", 'build', 'builder')
require 'rubygems'
require 'thor'
require 'fileutils'
require 'lib/openshift'
require 'pp'
require 'yaml'
require 'builder'

include FileUtils

module Origin
  class BuilderPlugin < OpenShift::Builder
    include OpenShift::BuilderHelper

    desc "build_livecd", "Build a livecd"
    def build_livecd
      basedir = "/root"
      remix_dir = "/root/origin-server/remix"
      remix_ks = "openshift-origin-remix.ks"  
      
      FileUtils.mkdir_p remix_dir
      git_rev = `git log --pretty="format:%H %cd" -1`
      
      system "rm -f #{remix_dir}/#{remix_ks}"
      ks_data = File.read("/usr/share/openshift/kickstarts/#{remix_ks}").gsub(/#ADDITIONAL REPOS/, "repo --name=local-build --baseurl=file://#{basedir}/origin-rpms\n#ADDITIONAL REPOS")
      ks_data.gsub!(/#GIT_REV#/,git_rev)
      
      if File.exist?("#{basedir}/extras")
        system "createrepo #{basedir}/extras"
        ks_data.gsub!(/#ADDITIONAL REPOS/, "repo --name=local-extras --baseurl=file://#{basedir}/extras\n#ADDITIONAL REPOS")
        #ks_data.gsub!(/#cartridge/,"cartridge")
      end
      File.open("#{remix_dir}/#{remix_ks}", 'w') do |out|
        out << ks_data
      end
      
      run "/sbin/service mongod stop"
      run "/usr/sbin/setenforce 0"
      run "cd #{remix_dir} && livecd-creator -c openshift-origin-remix.ks -f openshift_origin --cache=cache -d -v --logfile=livecd.log"
      run "/usr/sbin/setenforce 1"
      run "/sbin/service mongod start"
    end

    no_tasks do
      alias_method :old_install_required_packages, :install_required_packages
    end

    def install_required_packages
      base_os = guess_os
      puts "Install packages required for build"
      
      if `rpm -q activemq`.match(/is not installed/)
        run "yum erase -y activemq"
        if base_os == "fedora"
          run "yum install -y https://mirror.openshift.com/pub/origin-server/fedora-18/x86_64/activemq-5.6.0-4.fc18.x86_64.rpm"
          run %{ yum erase -y mcollective mcollective-common mcollective-client;\
                 yum install -y yum update -y https://mirror.openshift.com/pub/origin-server/fedora-17/x86_64/mcollective-2.2.0-2.fc17.noarch.rpm \
                 https://mirror.openshift.com/pub/origin-server/fedora-17/x86_64/mcollective-common-2.2.0-2.fc17.noarch.rpm \
                 https://mirror.openshift.com/pub/origin-server/fedora-17/x86_64/mcollective-client-2.2.0-2.fc17.noarch.rpm;
              }
        elsif(base_os == "rhel" or base_os == "centos")
          run "yum install -y activemq"
        end
      end
      
      if base_os == "fedora"
        run "yum -y update --enablerepo updates-testing ruby ruby-irb ruby-libs ruby-devel"
        run("gem install rspec -v '1.1.12'", options)
      end

      run "wget -O /etc/yum.repos.d/jenkins.repo http://pkg.jenkins-ci.org/redhat/jenkins.repo"
      run "rpm --import http://pkg.jenkins-ci.org/redhat/jenkins-ci.org.key"      
      run "yum install -y tito make tig mlocate bash-completion activemq-client"

      old_install_required_packages
    end
    
    desc "local_build", "Builds and installs all packages locally"
    method_option :base_os, :default => nil, :desc => "Operating system for Origin (fedora or rhel)"
    method_option :verbose, :type => :boolean, :desc => "Enable verbose logging"
    method_option :clean_packages, :type => :boolean, :desc => "Erase existing packages before install?"
    method_option :update_packages, :type => :boolean, :desc => "Run yum update before install?"
    method_option :incremental, :type => :boolean, :desc => "Build only the changed packages"
    def local_build
      options.verbose? ? $log.level = Logger::DEBUG : $log.level = Logger::ERROR
      def_constants(guess_os(options.base_os))
      
      if options.incremental
        options.retry_failure_with_tag = false
        update
      else
        FileUtils.rm_f "/etc/yum.repos.d/local-openshift-origin.repo"
        FileUtils.rm_rf "/tmp/tito"
        
        packages = get_packages(false, true).values

        if options.clean_packages?
          run("yum clean all", options)
          package_names = "\"#{packages.join("\" \"")}\""
          puts "Removing stale packages..."
          run("yum erase -y #{package_names}", options)
        end
        
        if options.update_packages?
          puts "Updating all packages on the system..."
          run("yum update -y", options)
          puts "Done"
        end

        find_and_build_specs

        FileUtils.rm_rf "/data/origin-rpms"
        FileUtils.rm_rf "/data/origin-srpms"
        FileUtils.mkdir_p "/data/origin-rpms"
        FileUtils.mkdir_p "/data/origin-srpms"        
        File.open("/etc/yum.repos.d/local-openshift-origin.repo", 'w') do |out|
          out << %{
[openshift-origin]
name    = openshift-origin
baseurl = file:///data/origin-rpms
gpgcheck= 0
enabled = 1
retries = 0
priority= 1
          }
        end
        run("cp /tmp/tito/x86_64/*.rpm /data/origin-rpms/; cp /tmp/tito/noarch/*.rpm /data/origin-rpms/; createrepo /data/origin-rpms/", options)
        run("cp /tmp/tito/*.src.rpm /data/origin-srpms/; chown -R #{SSH_USER}:#{SSH_USER} /data/origin-srpms", options)
        run("yum clean all")
        
        packages_to_install = packages.select{ |p| not IGNORE_PACKAGES.include?(p.name) }
        package_list = "\"#{packages_to_install.join("\" \"")}\""
        run("yum install -y #{package_list}", options)

        #mark all packages as sync'd
        get_sync_dirs
      end
    end


    no_tasks do
      def ssh_user
        return SSH_USER
      end

      def download_artifacts(hostname)
        puts "Downloading logs and screenshots..."
        `rm -rf rhc/log origin-rpms origin-srpms; mkdir -p rhc/log/; mkdir -p origin-rpms; mkdir -p origin-srpms; pushd rhc/log > /dev/null; mkdir -p broker ruby193-mcollective system screenshots selenium jbossas broker-profiler coverage; popd > /dev/null`
        scp_from(hostname, "/tmp/rhc/*", "rhc/log", 60, ssh_user)
        scp_from(hostname, "/var/log/openshift/broker/*", "rhc/log/broker", 60, ssh_user)
        scp_from(hostname, "/var/log/openshift/user_action.log", "rhc/log/broker/user_action.log", 60, ssh_user)
        scp_from(hostname, "/var/log/ruby193-mcollective.*", "rhc/log/ruby193-mcollective", 60, ssh_user)
        scp_from(hostname, "/var/log/httpd/access_log", "rhc/log/system/access_log.log", 60, ssh_user)
        scp_from(hostname, "/var/log/httpd/error_log", "rhc/log/system/error_log.log", 60, ssh_user)
        scp_from(hostname, "/var/log/yum.log", "rhc/log/system/yum.log", 60, ssh_user)
        scp_from(hostname, "/var/log/messages", "rhc/log/system/messages.log", 60, ssh_user)
        scp_from(hostname, "/var/log/secure", "rhc/log/system/secure.log", 60, ssh_user)
        scp_from(hostname, "/var/log/audit/audit.log", "rhc/log/system/audit.log", 60, ssh_user)
        scp_from(hostname, "/tmp/rhc/*_coverage", "rhc/log/coverage", 60, ssh_user)

        ssh(hostname, "sudo -s
          rm -rf /tmp/origin-rpms;
          mkdir -p /tmp/origin-rpms;
          cp -rf /data/origin-rpms/*.rpm /tmp/origin-rpms/;
          chown #{SSH_USER}:#{SSH_USER} -R /tmp/origin-rpms", 60, false, 2, ssh_user)
        scp_from(hostname, "/tmp/origin-rpms/*.rpm", "origin-rpms", 300, ssh_user)
        scp_from(hostname, "/data/origin-srpms/*.src.rpm", "origin-srpms", 300, ssh_user)
        puts "Done"
      end
      
      def validate_instance(hostname, num_tries=1)
      end
      
      def update_cucumber_tests(hostname, repo_parent_dir="/data", user="root")
        ssh(hostname, "
          rm -f #{repo_parent_dir}/openshift-test/tests; 
          ln -s #{repo_parent_dir}/openshift-test/controller/test/cucumber #{repo_parent_dir}/openshift-test/tests ;", 60, false, 2, user)
      end

      def setup_verifier(hostname, branch)
        update_remote_tests(hostname, branch, "/data", ssh_user)
      end

      def rpm_manifest(hostname, sshuser="root")
        print "Retrieving RPM manifest.."
        manifest = ssh(hostname, 'rpm -qa | grep -E "(rhc|openshift)" | grep -v cartridge', 60, false, 1, sshuser)
        manifest = manifest.split("\n").sort.join(" / ")
        # Trim down the output to 255 characters
        manifest.gsub!(/rubygem-([a-z])/, '\1')
        manifest.gsub!('openshift-origin-', '')
        manifest.gsub!('ruby193-mcollective-', 'mco-')
        manifest.gsub!('.fc16', '')
        manifest.gsub!('.noarch', '')
        manifest.gsub!(/\.git\.[a-z0-9\.]+/, '')
        manifest = manifest[0..254]
        puts "Done"
        return manifest
      end

      def idle_all_gears(hostname)
        puts "Idling all gears on remote instance: #{hostname}"
        ssh(hostname, "sudo bash -c /sbin/service ruby193-mcollective stop; /sbin/service ruby193-mcollective start;", 240, false, 1, options.ssh_user)
        ssh(hostname, 'for dir in /var/lib/openshift/*; do if [ -d $dir ] && [ ! -h $dir ] ; then sudo bash -c "oo-idler -n -u `basename $dir`"; fi; done;', 240, false, 1, options.ssh_user)
        ssh(hostname, 'sudo bash -c "/sbin/service httpd graceful"', 240, false, 1, options.ssh_user)
        puts "Done"
      end

      def test_impl(tag, hostname, instance, conn, options, image_id=nil)
        begin
          validate_instance(hostname, 4)
          mcollective_logs(hostname) if options.mcollective_logs?
          idle_all_gears(hostname) unless options.official?
          reset_test_dir(hostname, false, options.ssh_user)

          broker_profiler(hostname) if options.profile_broker?

          test_queues = [[], [], [], []]

          extended_tests = nil
          if options.include_extended
            extended_tests = []
            extended_tests = options.include_extended.split(",").map do |extended_test|
              extended_test.strip
            end
          end
 
          # Run oo-diagnostics on the host 
          # TODO filter out failures we don't care about and fail on others
          out, ret = ssh(hostname, "sudo -s oo-diagnostics", 60 * 20, true, 1, ssh_user)
          print_highlighted_output( "oo-diagnostics", out)
          oofails = out.scan(/FAIL: /).size
          if ret != 0 and oofails > 0
            # oofails == 3, since the default password failure is actually listed as 2 (since it is run from oo-accept-broker)
            unless oofails == 3 and out.match(/FAIL: test_enterprise_rpms/) and out.match(/FAIL: Datastore Password has been left configured as the default 'mooo'/)
              print_and_exit(ret, "oo-diagnostics failed for more than test_enterprise_rpms and default mongo password")
            end
          end

          ssh(hostname, "sudo yum install -y --disableplugin=priorities ruby193-rubygem-mocha", 60 * 5, true, 1, ssh_user)

          if options.include_extended
             # Some of the extended tests expect quickstarts.json to be non-empty
            ssh(hostname, %{ sudo bash -c "cat<<EOF > /etc/openshift/quickstarts.json
[
  {\"quickstart\": {
    \"id\": \"1\",
    \"name\":\"CakePHP\",
    \"website\":\"http://cakephp.org/\",
    \"initial_git_url\":\"git://github.com/openshift/cakephp-example.git\",
    \"cartridges\":[\"php-5\",\"mysql-5.1\"],
    \"summary\":\"CakePHP\",
    \"tags\":[\"php\",\"cakephp\",\"framework\"],
    \"admin_tags\":[]
  }}
]
EOF
            "}, 60 * 2, true, 1, options.ssh_user)

            # Some of the extended tests require that DEFAULT_MAX_GEARS be set to 3
            ssh(hostname, 'sudo sed -i "s/^DEFAULT_MAX_GEARS=.*/DEFAULT_MAX_GEARS=\"3\"/" /etc/openshift/broker-dev.conf; sudo service openshift-broker restart',
                60 * 2, true, 1, options.ssh_user) 

            extended_tests.each do |extended_test|
              case extended_test
              when 'broker'
                (1..4).each do |i|
                  test_queues[i-1] << build_cucumber_command("REST API Group #{i}", ["@broker_api#{i}", "~@not-enterprise"])
                end
                test_queues[0] << build_rake_command("OpenShift Broker Application System", "cd /data/openshift-test/broker; rake test:application_system_test", {}, true)
                test_queues[2] << build_rake_command("OpenShift Broker Cartridge System", "cd /data/openshift-test/broker; rake test:cartridge_system_test", {}, true)
                test_queues[0] << build_rake_command("OpenShift Broker Domain System", "cd /data/openshift-test/broker; rake test:domain_system_test", {}, true)
                test_queues[2] << build_rake_command("OpenShift Broker Functionals Ext", "cd /data/openshift-test/broker; rake test:functionals_ext")
                test_queues[3] << build_rake_command("OpenShift Broker Integration Ext", "cd /data/openshift-test/broker; rake test:integration_ext", {}, true)
              when 'runtime'
                (1..3).each do |i|
                  test_queues[i-1] << build_cucumber_command("Extended Runtime Group #{i}", ["@runtime_extended#{i}", "~@not-enterprise"])
                end
              when 'rhc'
                test_queues[1] << build_cucumber_command("RHC Integration",["~@not-enterprise"],
                                                         {"RHC_SERVER" => "localhost", "QUIET" => "1"},
                                                         nil,"cucumber", '*.feature', '/data/openshift-test/rhc',
                                                         nil, '/tmp/rhc_bundle')
              else
                puts "Not supported for extended: #{extended_test}"
                exit 1
              end
            end
          elsif options.include_cucumber
            timeout = @@SSH_TIMEOUT
            timeout = @@SSH_TIMEOUT_OVERRIDES[options.include_cucumber] if not @@SSH_TIMEOUT_OVERRIDES[options.include_cucumber].nil?
            test_queues[0] << build_cucumber_command(options.include_cucumber, ["@#{options.include_cucumber}"], nil, nil, "/data/openshift-test/tests")
          else
            unless options.exclude_broker?
              test_queues[3] << build_rake_command("OpenShift Broker Units", "cd /data/openshift-test/broker; rake test:units", {}, false)
              test_queues[0] << build_rake_command("OpenShift Broker Integration", "cd /data/openshift-test/broker; rake test:integration", {}, false)
              test_queues[2] << build_rake_command("OpenShift Broker Functional", "cd /data/openshift-test/broker; rake test:functionals", {}, false)
              test_queues[1] << build_rake_command("OpenShift Admin Console Functional", "cd /data/openshift-test/broker; rake test:admin_console_functionals", {}, false)
              test_queues[3] << build_cucumber_command("Broker Cucumber", ["@broker"], nil, nil, '/data/openshift-test/tests')
            end

            unless options.exclude_runtime?
              test_queues[0] << build_rake_command("Runtime Functional", "cd /data/openshift-test/node; rake essentials_test", {}, false)
              test_queues[1] << build_rake_command("Runtime Frontend Plugin ApacheDB", "cd /data/openshift-test/plugins/frontend/apachedb; rake test", {}, false)
              test_queues[2] << build_rake_command("Runtime Frontend Plugin Apache Mod Rewrite", "cd /data/openshift-test/plugins/frontend/apache-mod-rewrite; rake test", {}, false)
              test_queues[3] << build_rake_command("Runtime Frontend Plugin Apache Vhost", "cd /data/openshift-test/plugins/frontend/apache-vhost; rake test", {}, false)
              test_queues[0] << build_rake_command("Runtime Frontend Plugin NodeJS Websocket", "cd /data/openshift-test/plugins/frontend/nodejs-websocket; rake test", {}, false)
              test_queues[0] << build_rake_command("Runtime Frontend Plugin NodeJS Websocket", "cd /data/openshift-test/plugins/frontend/haproxy-sni-proxy; rake test", {}, false)
              (1..4).each do |i|
                test_queues[i-1] << build_cucumber_command("Runtime Group #{i.to_s}", ["@runtime#{i.to_s}"], nil, nil, '/data/openshift-test/tests')
              end
            end

            unless options.exclude_rhc?
              test_queues[0] << build_rake_command("RHC Spec", "cd /data/openshift-test/rhc; bundle install --path=/tmp/rhc_bundle && bundle exec rake spec", {}, false)
              test_queues[0] << build_rake_command("RHC Features", "cd /data/openshift-test/rhc; export TEST_INSECURE=1; export TEST_RANDOM_USER=1; export RHC_SERVER=localhost; bundle install --path=/tmp/rhc_bundle && bundle exec rspec features/*_feature.rb", {}, false)
            end
          end

          run_tests_with_retry(test_queues, hostname, options.ssh_user)

          #These are special tests that cannot be written to work concurrently
          singleton_queue = []
          if options.include_extended
            extended_tests.each do |extended_test|
              case extended_test
                when 'broker'
                when 'runtime'
                  idle_all_gears(hostname)
                  singleton_queue << build_cucumber_command("Runtime singletons", ["@singleton"], nil, nil, '/data/openshift-test/tests')
                when 'site'
                when 'rhc'
                else
                  puts "Not supported for extended: #{extended_test}"
                  exit 1
              end
            end
            run_tests_with_retry([singleton_queue], hostname, options.ssh_user)
          end
          validate_instance(hostname, 4)

          if options.official?
            image_id = image_id ? image_id : instance.image_id
            # Mark the image as verified
            image = conn.images[image_id]
            verify_image(image)

            puts "Sending QE ready email..."
            begin
              send_verified_email(image_id, image.name)
            rescue Exception => e
              puts "Failed sending email with message: #{e.message}"
            end
          elsif !options.terminate?
            idle_all_gears(hostname)
          end

          broker_profiler(hostname, enable=false) if options.profile_broker?

          puts "Done"

        ensure
          # add frontend config for any gears that may be left over from testing
          ssh(hostname, "sudo bash -c \"/usr/bin/oo-frontend-plugin-modify --rebuild --confirm\"", 120, false, 1, options.ssh_user)

          # reset quickstarts.json back to an empty list
          ssh(hostname, 'sudo bash -c echo "[]" > /etc/openshift/quickstarts.json', 60 * 2, true, 1, options.ssh_user) 

          # reset DEFAULT_MAX_GEARS="100"
          ssh(hostname, 'sudo sed -i "s/^DEFAULT_MAX_GEARS=.*/DEFAULT_MAX_GEARS=\"100\"/" /etc/openshift/broker-dev.conf; sudo service openshift-broker restart', 
              60 * 2, true, 1, options.ssh_user) 

          download_artifacts(hostname) if options.terminate?
          if options.terminate?
            terminate_instance(instance)
          end
        end
      end

      def sync_impl(name, options)
        # Get the hostname from a tag lookup or assume it's SSH accessible directly
        hostname = get_host_by_name_or_tag(name, options, ssh_user)

        clone_commands, working_dirs = sync_available_sibling_repos(hostname, options.branch, "/data", ssh_user)
        update_remote_tests(hostname, options.branch, "/data", ssh_user)
        
        ret = 0
        if !options.skip_build?
          puts "Performing remote install..."

          out, ret = ssh(hostname, "cd /data/ ; rm -rf #{working_dirs}; #{clone_commands}", 60 * 5, true, 1, ssh_user)
          print_and_exit(ret, out) if ret != 0

          out, ret = ssh(hostname, "sudo -s yum clean metadata", 60 * 2, true, 2, ssh_user) if options.clean_metadata?
          print_and_exit(ret, out) if ret != 0

          cmd = "build/devenv update"
          cmd += " --verbose" if options.verbose
          cmd += " --include_stale" if options.clean_metadata

          if(BASE_OS == "rhel" or BASE_OS == "centos")
            cmd = "scl enable ruby193 \"#{cmd}\""
          end
          out, ret = ssh(hostname, "cd /data/#{DEV_TOOLS_EXT_REPO}; sudo -s #{cmd}  2>&1 ", 60 * 15, true, 1, ssh_user) if ret == 0
          print_and_exit(ret, out) if ret != 0

          out, ret = ssh(hostname, "sudo -s #{options.clean_metadata? ? "yum update -y rhc *openshift*" : ''}", 60 * 15, true, 1, ssh_user) if options.clean_metadata?
          print_and_exit(ret, out) if ret != 0
          
          post_launch_setup(hostname, options)
        end

        puts "Done"
      end
  
      def build_impl(name, build_num, image, conn, options)
        if options.install_required_packages?
          $amz_options[:user_data] = "#!/bin/bash\nset -x\necho Defaults:root,ec2-user \!requiretty >> /etc/sudoers\nsed -i '/cat <<EOL/,$d' /etc/rc.local\nsed -i 's/PermitRootLogin without-passwordUseDNS no/PermitRootLogin without-password\nUseDNS no/g' /etc/ssh/sshd_config\n"
        else
          $amz_options[:user_data] = "#!/bin/bash\nset -x\nsed -i '/cat <<EOL/,$d' /etc/rc.local\nsed -i 's/PermitRootLogin without-passwordUseDNS no//g' /etc/ssh/sshd_config\n"
        end
        puts "Launching AMI: #{image.id} - #{image.name}"
        instance = launch_instance(image, name + "_" + build_num, 1, ssh_user)

        hostname = instance.dns_name

        puts "Building on: #{hostname}"

        begin
          if options.install_required_packages?
            puts "Uploading yum client certificates..."
            pem_path = File.expand_path(File.dirname(__FILE__) + "/../misc/client-cert.pem")
            scp_to(hostname, pem_path, "~/", 60*10, 5, ssh_user)
            ssh(hostname, "sudo -s mv ~/client-cert.pem /var/lib/yum/", 60 * 10, true, 1, ssh_user)
            pem_path = File.expand_path(File.dirname(__FILE__) + "/../misc/client-key.pem")
            # needed for init_repos
            scp_to(hostname, pem_path, "~/", 60*10, 5, ssh_user)
            ssh(hostname, "sudo -s mv ~/client-key.pem /var/lib/yum/", 60 * 10, true, 1, ssh_user)
            scp_to(hostname, "misc/devenv/root/.ssh/*", "~/.ssh/", 60*10, 5, ssh_user)
            ssh(hostname, "sudo -s chmod 0600 ~/.ssh/id_rsa; sudo -s chmod 0644 ~/.ssh/id_rsa.pub ~/.ssh/known_hosts;",
                           60*10, true, 1, ssh_user)
            puts "Done"

            puts "Setting up yum repos..."
            script_path = File.expand_path(File.dirname(__FILE__) + "/../misc/devenv/setup-devenv-repos.sh")
            scp_to(hostname, script_path, "~/", 60*10, 5, ssh_user)
            ssh(hostname, "sudo -s /bin/bash ~/setup-devenv-repos.sh #{options.yum_repo};", 1800, true, 1, ssh_user)
            puts "Done"

            puts "Setting up yum priorities..."
            out, ret = ssh(hostname, "sudo -s yum -y install yum-plugin-priorities", 60 * 20, true, 1, ssh_user)
            print_and_exit(ret, out) if ret != 0
            print_highlighted_output("Update Output", out)
            repo = 'rhui-us-east-1-rhel-server-releases'
            out, ret = ssh(hostname, "sudo -s yum-config-manager --setopt=#{repo}.priority=2 #{repo} --save", 60 * 20, 
                           true, 1, ssh_user)
            out, ret = ssh(hostname, "sudo -s yum-config-manager --setopt='#{repo}.exclude=tomcat6*' #{repo} --save", 60 * 20, 
                           true, 1, ssh_user)
            print_and_exit(ret, out) if ret != 0
            print_highlighted_output("Update Output", out)
            out, ret = ssh(hostname, "sudo -s yum install -y rh-amazon-rhui-client-jbeap6 rh-amazon-rhui-client-jbews2", 60 * 20, true, 1, ssh_user)
            print_and_exit(ret, out) if ret != 0
            print_highlighted_output("Update Output", out)
            repos = ['rhui-us-east-1-jbeap-6-rhui-rhel-6-rpms', 'rhui-us-east-1-rhel-server-6-jbews2'] 
            repos.each do |repo|
              out, ret = ssh(hostname, "sudo -s yum-config-manager --setopt=#{repo}.priority=3 #{repo} --save", 
                             60 * 20, true, 1, ssh_user)
              print_and_exit(ret, out) if ret != 0
              print_highlighted_output("Update Output", out)
            end

            #out, ret = ssh(hostname, "sudo -s yum install -y git rubygem-thor rubygem-cucumber rubygem-rspec rubygem-webmock", 60 * 10, true, 1, ssh_user)
            #print_and_exit(ret, out) if ret != 0
            #print_highlighted_output("Install Output", out)
          end

          puts "Updating all packages on the system..."
          out, ret = ssh(hostname, "sudo yum clean metadata; sudo -s yum -y update", 60 * 20, true, 1, ssh_user)
          print_and_exit(ret, out) if ret != 0
          print_highlighted_output("Update Output", out)

          puts "Creating mount..."
          if options.install_from_source? || options.install_from_local_source?
            out, ret = ssh(hostname, "sudo -s rm -rf /data", 60 * 10, true, 1, ssh_user)
            print_and_exit(ret, out) if ret != 0
          end
          out, ret = ssh(hostname, "sudo -s mkdir -p /data && sudo -s chown -R #{SSH_USER}:#{SSH_USER} /data/", 60 * 10, true, 1, ssh_user)
          print_and_exit(ret, out) if ret != 0

          output = ''
          clone_commands = repo_clone_commands(hostname)
          cmd = "set -ex;"
          if options.install_from_source? || options.install_from_local_source?
            if options.install_from_source?
              puts "Performing clean install from source..."
            elsif options.install_from_local_source?
              puts "Performing clean install from local source..."
            end
            init_repos(hostname, true, nil, "/data", ssh_user)
            sync_repos(hostname, "/data", ssh_user) if options.install_from_local_source?
            cmd += %{ pushd /data 
#{clone_commands}
popd
mkdir -p /tmp/tito
}
            wantedbranch = options.install_from_source? ? options.branch : "master"
            SIBLING_REPOS.each_key do |repo_name|
              cmd += "pushd /data/#{repo_name}; git checkout #{wantedbranch}; popd;"
            end
            cmd += %{
pushd /data/#{DEV_TOOLS_EXT_REPO} > /dev/null
  echo "Building all packages on the server..."
  sudo -s scl enable ruby193 "build/devenv local_build --clean-packages"
popd > /dev/null

}
          elsif options.install_required_packages?
            puts "Installing bootstrap packages..."
            output, exit_code = ssh(hostname, "sudo -s yum install -y ruby193-ruby ruby193-rubygem-thor ruby193-rubygem-capybara ruby193-rubygem-ci_reporter ruby193-rubygem-minitest ruby193-rubygem-mocha ruby193-rubygem-poltergeist ruby193-rubygem-simplecov ruby193-rubygem-webmock ruby193-rubygem-net-ssh-multi ruby193-rubygem-net-ssh-gateway ruby193 scl-utils ruby193-rubygem-aws-sdk ruby193-rubygem-parseconfig", 60 * 20, true, 1, ssh_user)

            #output, exit_code = ssh(hostname, "yum -y install git tito ruby rubygems rubygem-thor rubygem-parseconfig rubygem-json rubygem-aws-sdk ruby193-rubygem-thor ruby193-rubygem-parseconfig ruby193-rubygem-json ruby193-rubygem-aws-sdk scl-utils-build createrepo yum-priorities", 600, true)
            print_highlighted_output('Install Bootstrap Packages Output', output)
            exit 1 unless exit_code == 0
            puts "Install more bootstrap packages..."
            output, exit_code = ssh(hostname, "sudo yum install -y --enablerepo=puppetlabs-products --enablerepo=epel --disablerepo=Node puppet-2.7.21 tito", 60 * 15, true, 1, ssh_user) if ret == 0
            print_highlighted_output('Install More Bootstrap Packages Output', output)
            exit 1 unless exit_code == 0
            puts "Done"

            puts "Installing requires..."
            init_repos(hostname, true, nil, "/data", ssh_user)
            cmd += %{ pushd /data
#{clone_commands} 
popd
}
            SIBLING_REPOS.each_key do |repo_name|
              cmd += "pushd /data/#{repo_name}; git checkout #{options.branch}; popd;"
            end
            cmd += %{
pushd /data/#{DEV_TOOLS_EXT_REPO}
  sudo -s scl enable ruby193 "build/devenv install_required_packages" 2>&1
popd
sudo -s rm -rf /etc/puppet/modules &&
  sudo -s mkdir -p /etc/puppet/modules &&
  sudo -s puppet module install puppetlabs/stdlib &&
  sudo -s puppet module install puppetlabs/ntp &&
  sudo -s ln -sf /data/puppet-openshift_enterprise /etc/puppet/modules/openshift_origin
}
          else
            puts "Performing clean install with the last published rpms..."
          end

          output, exit_code = ssh(hostname, cmd, 3600, true, 1, ssh_user)
          print_highlighted_output('Install Output', output)
          puts "Done"
          exit exit_code unless exit_code == 0

          # Cleanup any lines that break sshd_config (cloud-init RHEL 6.4 bug)
          puts "Cleaning up broken sshd_config (RHEL 6.4 cloud-init bug)"
          ssh(hostname, 'sudo -s sed -i "s/PermitRootLogin without-passwordUseDNS no//g" /etc/ssh/sshd_config', 60, true, 1, ssh_user)

          output = ssh(hostname, "sudo yum list installed", 120, true, 1, ssh_user)
          print_highlighted_output('Installed Packages', output)

          image_id = nil
          if options[:register]
            # reset the eth0 network config to remove the HWADDR
            puts "Removing HWADDR and DNS entries from eth0 network config..."
            reset_eth0_dns_config(hostname)
            
            manifest = rpm_manifest(hostname, ssh_user)              
            registered_ami = register_image(conn, instance, name + '_' + build_num, manifest)
            image_id = registered_ami.id
          end

          unless options.install_required_packages?  
            puts "Running post_launch_setup..."
            post_launch_setup(hostname, options)
          end

          unless options.skip_verify? || options.install_required_packages?
            update_remote_tests(hostname, options.branch, "/data", options.ssh_user)
            test_impl(name + '_' + build_num, hostname, instance, conn, options, image_id)
          end
        ensure
          begin
            terminate(name + '_' + build_num) if options.terminate?
          rescue
            # suppress termination errors - they have been logged already
          end
        end
      end

      def reset_eth0_dns_config(hostname)
cmd = %{
sudo -s echo \\\"DEVICE=eth0
BOOTPROTO=dhcp
ONBOOT=yes
\\\" > /etc/sysconfig/network-scripts/ifcfg-eth0

sudo -s /etc/init.d/network restart
sudo -s service named restart
}
        out, ret = ssh(hostname, cmd, 60 * 5, true, 1, ssh_user)
        print_and_exit(ret, out) if ret != 0
      end
  
      def sanity_check_impl(tag, hostname, instance, conn, options, image_id=nil)
        threads = []
        failures = []
        titles = ["OpenShift Origin Broker Sanity",
                  "OpenShift Origin Node Unit"]
    
        cmds = ["cd /var/www/openshift/broker; sudo -s bundle exec rake test:sanity",
                "cd /data/openshift-test/node; sudo -s rake unit_test"]
        add_ssh_cmd_to_threads(hostname, threads, failures, titles, cmds, false, @@SSH_TIMEOUT, ssh_user)
        add_ssh_cmd_to_threads(hostname, threads, failures, "Cucumber Sanity", "cucumber #{CUCUMBER_OPTIONS} -t @sanity /data/openshift-test/tests/", false, @@SSH_TIMEOUT, ssh_user)
    
        threads.each do |t|
          t[0].join
        end
    
        unless failures.empty?
          failures.uniq!
          retry_test_failures(hostname, failures, 1, @@SSH_TIMEOUT, ssh_user)
        end
      end
      
      def update_facts_impl(hostname)
      end

      def update_puppet_manifests(hostname, options, authtype)
        out, ret = ssh(hostname, %{
cat<<EOF > ~#{options.ssh_user}/configure_hostname.pp
file { "update network settings - hostname": 
  path    => "/etc/sysconfig/network",
  content => "NETWORKING=yes\nNETWORKING_IPV6=no\nHOSTNAME=\\\${ec2_public_hostname}\n"
}
exec { "set hostname":
  command => "/bin/hostname \\\${ec2_public_hostname}"
}
EOF
        }, 60 * 2, true, 1, options.ssh_user)
        print_and_exit(ret, out) if ret != 0
        out, ret = ssh(hostname, %{
cat<<EOF > ~#{options.ssh_user}/configure_origin.pp
\\\$keyfile="/var/named/Kdev.rhcloud.com.*.key"
\\\$key=inline_template("<%=File.read(Dir.glob(keyfile)[0]).strip.split(\' \')[7]%>")
class { "openshift_origin" :
  node_fqdn              => \\\$ec2_public_hostname,
  broker_fqdn            => "broker.dev.rhcloud.com",
  cloud_domain           => "dev.rhcloud.com",
  named_tsig_priv_key    => \\\$key,
  dns_servers            => ["172.16.0.23"],
  os_unmanaged_users     => ["#{options.ssh_user}"],
  install_repo           => "file:///data/origin-rpms",
  development_mode       => true,
  configure_cgroups      => true,
  broker_auth_plugin     => "#{authtype}",
  configure_ntp          => false,
  broker_auth_salt       => 'ClWqe5zKtEW4CJEMyjzQ2',
  broker_session_secret  => 'devenv_secret',
  console_session_secret => 'devenv_secret',
}
EOF
        }, 60 * 2, true, 1, options.ssh_user)
        print_and_exit(ret, out) if ret != 0
      end
      
      def post_launch_setup(hostname, options)                        
        puts "Setting machine hostname"
        update_puppet_manifests(hostname, options, "basic-auth")
 
        # reset the eth0 network config to add the dns entries
        out, ret = ssh(hostname, "sudo -s puppet apply --verbose ~#{SSH_USER}/configure_hostname.pp", 60 * 20, true, 1, ssh_user)
        print_and_exit(ret, out) if ret != 0
        
        ssh(hostname, 'sudo -s rm -rf /var/named/Kdev.rhcloud.com*', 60 * 20, true, 1, ssh_user)
        out, ret = ssh(hostname, 'sudo -s yum install -y bind', 60 * 20, true, 1, ssh_user)
        print_and_exit(ret, out) if ret != 0
        out, ret = ssh(hostname, 'sudo -s /usr/sbin/dnssec-keygen -a HMAC-MD5 -b 512 -n USER -r /dev/urandom -K /var/named dev.rhcloud.com', 60 * 20, true, 1, ssh_user)
        print_and_exit(ret, out) if ret != 0
        out, ret = ssh(hostname, 'TSIG_KEY=`sudo -s cat /var/named/Kdev.rhcloud.com.*.key | awk "{ print $8 }"` ; echo $TSIG_KEY', 60 * 20, true, 1, ssh_user)
        print_and_exit(ret, out) if ret != 0

        out, ret = ssh(hostname, 'sudo -s rm -f /etc/openshift/.mongo-setup-complete', 60 * 20, true, 1, ssh_user)
        out, ret = ssh(hostname, "sudo -s puppet apply --verbose ~#{SSH_USER}/configure_origin.pp", 60 * 20, true, 1, ssh_user)
        print_and_exit(ret,out) if ret != 0
        print_highlighted_output( "Puppet", out )

        # Overwrite iptables rules after puppet run
        iptables_path = File.expand_path(File.dirname(__FILE__) + "/../misc/iptables")
        scp_to(hostname, iptables_path, "~/", 60*10, 5, ssh_user)
        ssh(hostname, "sudo -s mv iptables /etc/sysconfig/iptables; sudo restorecon /etc/sysconfig/iptables; sudo service iptables restart", 60 * 20, true, 1, ssh_user)

        # TODO: activemq is failing to start or crashing
        out, ret = ssh(hostname, "sudo -s service activemq restart; sleep 10; sudo -s service ruby193-mcollective restart", 60 * 20, true, 1, ssh_user)
        print_and_exit(ret, out) if ret != 0
        print_highlighted_output( "Service Restart", out)
        restart_services_remote(hostname)

        # TODO: find out why the %post section of the cartridge rpms is failing without showing up in output
        out, ret = ssh(hostname, "sudo -s oo-admin-cartridge -a install -R -s /usr/libexec/openshift/cartridges/v2/", 60 * 20, true, 1, ssh_user)
        print_and_exit(ret, out) if ret != 0
        print_highlighted_output( "Verify all cartridges installed into cartridge repository", out)
       
        # Remove abrt-addon-python until https://bugzilla.redhat.com/show_bug.cgi?id=907449 is resolved
        out, ret = ssh(hostname, "sudo -s yum remove -y abrt-addon-python", 60 * 20, true, 1, ssh_user)
        print_highlighted_output( "Removing abrt-addon-python for bz907449", out)
      end

      def restart_services
        cmd = %{
        sudo -s service activemq restart; sudo -s service mongod restart
        sudo -s service cgconfig restart; sudo -s service cgred restart ; sudo -s service openshift-cgroups restart
        sudo -s service httpd restart; sudo -s service openshift-broker restart
        sudo -s service openshift-console restart; 
        sudo -s service openshift-node-web-proxy stop; 
        sudo -s service named restart; sudo -s service network restart
        sudo -s service ruby193-mcollective restart; sudo -s service oddjobd restart
        sudo -s service openshift-node-web-proxy start;
        sudo -s service openshift-iptables-port-proxy restart; sudo -s service openshift-tc restart
        }
        run(cmd)
      end

      def restart_services_remote(hostname)
        puts "Restarting services..."

        cmd = %{
sudo -s service activemq restart; sudo -s service mongod restart
sudo -s service httpd restart; sudo -s service openshift-broker restart
sudo -s service openshift-console restart; 
sudo -s service openshift-node-web-proxy stop;
sudo -s service named restart; sudo -s service network restart
sudo -s service cgconfig restart; sudo -s service cgred restart ; sudo -s service openshift-cgroups restart
sudo -s service ruby193-mcollective restart; sudo -s service oddjobd restart
sudo -s service openshift-node-web-proxy start;
sudo -s service openshift-iptables-port-proxy restart; sudo -s service openshift-tc restart
}
        out, ret = ssh(hostname, cmd, 60 * 5, true, 1, ssh_user)
        print_and_exit(ret, out) if ret != 0
        puts "Done"
      end
    end # no_tasks end
  end # class end
end # module end
Origin::BuilderPlugin.start
